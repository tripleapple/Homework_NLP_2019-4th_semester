#Basic theorietical:
0. Can you come up out 3 sceneraies which use AI methods?
Ans: [system automatically create news release with given material,intellegence sound device understand your language and operate your 
commands,system calculates the optimal routing to the trucks for the delivery in logistics]

1. How do we use Github; Why do we use Jupyter and Pycharm;
Ans: {We use Github to exchange codings with each other. The display style of the Jupyter is better, and it enables to mark with titles,
remarks, and process the coding at the same time. Pycharm could support us to manage the coding under project style. It could manage
different projects in different documents, while at the same time could be called each other with certain reminders.}

2. What's the Probability Model?
Ans: Probability model is based on the concept that incident happens often in the past is supposed to happen more often than it's expected
in the future. 

3. Can you came up with some sceneraies at which we could use Probability Model?
Ans: Games such as Poker, dice; find potential risks in industrial(to check whether the probability out of control); whether forcast.

4. Why do we use probability and what's the difficult points for programming based on parsing and pattern match?
Ans: Probability meets the natual patterns and could solve uncertainty problems. The computing complexity will be factorial if consider all relationships.

5. What's the Language Model;
Ans: Based on the history languages, calculate the probability of the new languages(sentences) are reasonable by checking phrase relations probability.

6. Can you came up with some sceneraies at which we could use Language Model?
Ans: "Jieba" algorithm itself may have used part of the language model. Analyze the phrasing styles of a writer.

7. What's the 1-gram language model;
Ans: Based on language model, in order to reduce the complexitiy of the program, only consider the probabilities of each phrase and omit the relations between them.

8. What's the disadvantages and advantages of 1-gram language model;
Ans: It only considers the phrase probability, and does not consider the phrase relations within the sentance at all.

9. What't the 2-gram models;
Ans: Based on language model, in order to reduce the complexitiy of the program, only consider the probabilities of 2 neighbouring phrases,
and omit the relations between phrases with further distance.

#Practical:
host = """
host = 寒暄  报数  询问  业务相关  结尾 
报数 = 我是 | 数字 | 号 ,
数字 = 单个数字 | 数字 单个数字
单个数字 = 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 
寒暄 = 称谓 打招呼 | 打招呼
称谓 = 人称 ,
人称 = 先生 | 女士 | 小朋友
打招呼 = 你好 | 您好 
询问 = 请问你要 | 您需要
业务相关 = 玩玩 具体业务
玩玩 = 耍一耍 | 玩一玩
具体业务 = 喝酒 | 打牌 | 打猎 | 赌博
结尾 = 吗？
"""
def create_grammar(grammar_str, split='=', line_split='\n'):
    grammar = {}
    for line in grammar_str.split(line_split):
        if not line.strip(): continue
        exp, stmt = line.split(split)
        grammar[exp.strip()] = [s.split() for s in stmt.split('|')]
    return grammar

def generate(gram, target):
    if target not in gram: return target
    expaned = [generate(gram, t) for t in random.choice(gram[target])]
    return ''.join([e if e != '/n' else '\n' for e in expaned if e != 'null'])
#print(create_grammar(host))
def generate_n(n):
    for repeat in range(n):
        print(generate(gram=create_grammar(host), target = "host"))
#print(create_grammar(host))
#print(generate(gram=create_grammar(host), target = "host"))
print(generate_n(2))


